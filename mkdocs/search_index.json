{
    "docs": [
        {
            "location": "/",
            "text": "Welcome\n\n\nThis is a place where I'll write down some of the things I've learned to help others save some time and energy.\n\n\nDiscussions\n\n\n\n\nBenchmarking Python Serializers\n - outcome of a little research into the various mechanisms for marshalling Python objects.\n\n\n\n\nMy Projects\n\n\nEssentialDB\n is a NoSQL document database written in pure Python with similar query syntax to mongo.\n\n\nEssential Magic Mirror\n is a hobby project for the raspberry pi.",
            "title": "Home"
        },
        {
            "location": "/#welcome",
            "text": "This is a place where I'll write down some of the things I've learned to help others save some time and energy.",
            "title": "Welcome"
        },
        {
            "location": "/#discussions",
            "text": "Benchmarking Python Serializers  - outcome of a little research into the various mechanisms for marshalling Python objects.",
            "title": "Discussions"
        },
        {
            "location": "/#my-projects",
            "text": "EssentialDB  is a NoSQL document database written in pure Python with similar query syntax to mongo.  Essential Magic Mirror  is a hobby project for the raspberry pi.",
            "title": "My Projects"
        },
        {
            "location": "/python_serializers/",
            "text": "2017-01-06\n\n\nAfter measuring \nEssentialDB's performance\n, I did some basic profiling and it became very clear that serializing and deserializing objects to disk was the biggest bottleneck and most likely the best opportunity for quick performance boosts. Initial \nresearch\n suggested that \nswapping out pickle\n for a json based library would provide instant performance gains. I was excited - I might cut my write times by \norders of magnitude\n with a one line code change! But early experiments simply didn't back \nthese claims\n. Rather than gaining by orders of magnitude, things got slower. I decided to run some benchmarks of my own and this is what I found.\n\n\nWhat is serialization and deserialization\n\n\nBasically, you have an object and you want to be able to send across the network or persist it to disk in its current state. To do that, you have to \nserialize\n the object into a character or byte stream. On the other side, you will need to \ndeserialize\n the character or byte stream into an object with the same state.\n\n\nPython (De)Serialization\n\n\nThere are several popular modules available using several different techniques for (de)serialization in Python. For this document, we tested the following:\n\n\n\n\npickle\n - This is the standard for serializing Python objects to disk. Pickle format is \nnot portable\n since it can only be read by Python programs.\n\n\nMarshal\n - This is an internal Python module used for the generation of code objects. The documentation warns strongly against using this for general persistence since it does not ensure compatibility between Python versions. Marshal files are \nnot portable\n since they can only be read by Python programs.\n\n\njson\n - The standard python module for serializing Python objects to and from JavaScript Object Notation (JSON) representation. Most programming languages can read JSON.\n\n\nsimplejson\n - Alternate module for python serialization. Most programming languages can read JSON.\n\n\nujson\n - Alternate module for python serialization backed with a compiled C library. While very fast, the compiled portion makes it difficult to install on some platforms. Most programming languages can read JSON.\n\n\nmsgpack\n - Python module for serializing Python objects to and from the very compact \nMessagePack\n binary serialization format. This module is backed by a C library for speed. Most programming languages can read MessagePack.\n\n\numsgpack\n - Pure python implementation of the MessagePack format.\n\n\n\n\nThere are plenty of other formats and modules that I didn't include in these tests for a variety of reasons. For example, tests using \nYAML\n took so long that my console kept timing out while waiting on them to complete.\n\n\nThe Tests\n\n\nI used EssentialDB's fake \ndocument generator\n to generate objects with the following template:\n\n\ntemplate = {\n    \"f0\": \"integer\",    #A positive integer\n    \"f1\": \"short_int\",  #An int between 0 and 100\n    \"f2\": \"sentence\",   #A string of 3 to 15 words\n    \"f3\": \"email\",      #An email address\n    \"f4\": \"url\",        #A website URL\n    \"f5\": \"paragraph\",  #A string of 3 to 15 sentences\n    \"f6\": \"floating\",   #A floating point number\n    \"f7\": ['one', 'two', 'three', 'four'] #One of the 4 choices\n}\n\n\n\n\n\nGenerate 100,000 objects (dictionaries)\n\n\nFor each of the modules\n\n\nStart the write timer\n\n\nFor 1 to 10\n\n\nserialize the objects to disk\n\n\n\n\n\n\nStop the write timer\n\n\nStart the read timer\n\n\nFor 1 to 10\n\n\ndeserialize the objects from disk\n\n\n\n\n\n\nStop the read timer\n\n\n\n\n\n\n\n\nYou can find the \nfull source code here\n.\n\n\nThe tests were ran on an Amazon AWS t2.small running stock Ubuntu with Python 3.5.\n\n\nThe Results\n\n\nThe following figure show the average of 10 reads/writes of 100K objects with each (de)serializer. Read and writes are in seconds and size is in megabytes on disk of the serialized objects.\n\n\n\n\n\n\nThis table shows the raw results.\n\n\n\n\n\n\n\n\nModule\n\n\nWrite\n\n\nRead\n\n\nSize\n\n\n\n\n\n\n\n\n\n\npickle\n\n\n1.362\n\n\n0.321\n\n\n88.110\n\n\n\n\n\n\nmarshal\n\n\n1.353\n\n\n1.480\n\n\n88.050\n\n\n\n\n\n\njson\n\n\n2.812\n\n\n0.555\n\n\n92.287\n\n\n\n\n\n\nsimplejson\n\n\n3.166\n\n\n0.550\n\n\n92.287\n\n\n\n\n\n\nujson\n\n\n1.463\n\n\n0.638\n\n\n91.127\n\n\n\n\n\n\numsgpack\n\n\n3.940\n\n\n4.050\n\n\n86.048\n\n\n\n\n\n\nmsgpack\n\n\n1.342\n\n\n0.388\n\n\n86.048\n\n\n\n\n\n\n\n\nWhat does this mean?\n\n\nFrom the data above, we can see that pickle and msg-pack performed the best overall. In my initial research, I read several benchmarks claiming that JSON, particularly ujson, would provide enhanced performance over pickle - but that is not reflected in my test results at all. Why were my results different?\n\n\nMost of the existing bench marks out there appear to be based on Python2 and these tests were performed on Python3 - which is a very important distinction. Python has two implementations of the pickle module, refered to as cPickle (backed by a C library for speed) and Pickle (a pure Python implementation for portability). In Python2, pickle is loaded by default and required the programmer to use a construct like:\n\n\ntry:\n   import cPickle as pickle\nexcept:\n   import pickle\n\n\n\nIn Python3, cPickle was renamed to _pickle and is now automatically loaded when present. If not present, Python will automatically fall back to the pure python implementation. Additionally, Python version 3.0 introduced Protocol 3 and version 3.4 introduced Protocol 4 - both adding significant enhancements and performance boosts to the binary pickle formats.\n\n\nThe end result of these improvements is that the old best practices for Python serialization don't hold up any more. This is how I will be making my choices:\n\n\n\n\nIf speed, convenience and flexibility are the most important, choose pickle.\n\n\nFastest round trip in my test cases\n\n\nPython built-in, so \nimport pickle\n just works\n\n\nMost Python object support it already, so they automatically (de)serialize\n\n\n\n\n\n\nIf speed and portability are the most important, choose msg-pack\n\n\nSecond fastest round trip in my tests cases\n\n\nSerial format has support in over 50 programming language\n\n\nBut requires a C-Module, so you might need a compiler if you can't find a binary release for your platform\n\n\n\n\n\n\nIf speed and JSON format are the most important, use ujson\n\n\nThird fastest round trip\n\n\nOutputs compliant JSON, which has become the de-facto exchange format\n\n\nBut requires a C-Module, so you might need a compiler if you can't find a binary release for your platform\n\n\n\n\n\n\nIf convenience and JSON format are the most important factors, use the built-in json module.\n\n\nFourth fastest round trip time\n\n\nOutputs compliant JSON, which has become the de-facto exchange format\n\n\nPython built-in, so \nimport json\n just works\n\n\n\n\n\n\n\n\nFor the EssentialDB Use Case\n\n\nEssentialDB doesn't support any partitioning or sharding currently (since it is generally meant to be used in memory) so the entire database is serialized and deserialized to disk at once - so speed (throughput) is the most important factor in many use cases. Many, but not all cases. Based on this, it makes sense that EssentialDB should support all of the serialization modules listed above. There are valid use cases to prefer any of the formats. Each of the module discussed here implement the same Python serialization interface:\n\n\n# read - fp is a file object\ndata = serializer.load(fp)\n#write\nserializer.dump(fp, data)\n\n\n\nBy exploiting this, we can have pickle be the default serializer, but allow developers to specify alternate serializers.\n\n\nThe \npickle documentation \n has a great discussion on when the differences in the formats:\n\n\n\n\nJSON is a text serialization format (it outputs unicode text, although most of the time it is then encoded to utf-8), while pickle is a binary serialization format;\n\n\nJSON is human-readable, while pickle is not;\n\n\nJSON is interoperable and widely used outside of the Python ecosystem, while pickle is Python-specific;\n\n\nJSON, by default, can only represent a subset of the Python built-in types, and no custom classes; pickle can represent an extremely large number of Python types (many of them automatically, by clever usage of Python\u2019s introspection facilities; complex cases can be tackled by implementing specific object APIs).",
            "title": "Python (De)Serializers Benchmarks"
        },
        {
            "location": "/python_serializers/#what-is-serialization-and-deserialization",
            "text": "Basically, you have an object and you want to be able to send across the network or persist it to disk in its current state. To do that, you have to  serialize  the object into a character or byte stream. On the other side, you will need to  deserialize  the character or byte stream into an object with the same state.",
            "title": "What is serialization and deserialization"
        },
        {
            "location": "/python_serializers/#python-deserialization",
            "text": "There are several popular modules available using several different techniques for (de)serialization in Python. For this document, we tested the following:   pickle  - This is the standard for serializing Python objects to disk. Pickle format is  not portable  since it can only be read by Python programs.  Marshal  - This is an internal Python module used for the generation of code objects. The documentation warns strongly against using this for general persistence since it does not ensure compatibility between Python versions. Marshal files are  not portable  since they can only be read by Python programs.  json  - The standard python module for serializing Python objects to and from JavaScript Object Notation (JSON) representation. Most programming languages can read JSON.  simplejson  - Alternate module for python serialization. Most programming languages can read JSON.  ujson  - Alternate module for python serialization backed with a compiled C library. While very fast, the compiled portion makes it difficult to install on some platforms. Most programming languages can read JSON.  msgpack  - Python module for serializing Python objects to and from the very compact  MessagePack  binary serialization format. This module is backed by a C library for speed. Most programming languages can read MessagePack.  umsgpack  - Pure python implementation of the MessagePack format.   There are plenty of other formats and modules that I didn't include in these tests for a variety of reasons. For example, tests using  YAML  took so long that my console kept timing out while waiting on them to complete.",
            "title": "Python (De)Serialization"
        },
        {
            "location": "/python_serializers/#the-tests",
            "text": "I used EssentialDB's fake  document generator  to generate objects with the following template:  template = {\n    \"f0\": \"integer\",    #A positive integer\n    \"f1\": \"short_int\",  #An int between 0 and 100\n    \"f2\": \"sentence\",   #A string of 3 to 15 words\n    \"f3\": \"email\",      #An email address\n    \"f4\": \"url\",        #A website URL\n    \"f5\": \"paragraph\",  #A string of 3 to 15 sentences\n    \"f6\": \"floating\",   #A floating point number\n    \"f7\": ['one', 'two', 'three', 'four'] #One of the 4 choices\n}   Generate 100,000 objects (dictionaries)  For each of the modules  Start the write timer  For 1 to 10  serialize the objects to disk    Stop the write timer  Start the read timer  For 1 to 10  deserialize the objects from disk    Stop the read timer     You can find the  full source code here .  The tests were ran on an Amazon AWS t2.small running stock Ubuntu with Python 3.5.",
            "title": "The Tests"
        },
        {
            "location": "/python_serializers/#the-results",
            "text": "The following figure show the average of 10 reads/writes of 100K objects with each (de)serializer. Read and writes are in seconds and size is in megabytes on disk of the serialized objects.    This table shows the raw results.     Module  Write  Read  Size      pickle  1.362  0.321  88.110    marshal  1.353  1.480  88.050    json  2.812  0.555  92.287    simplejson  3.166  0.550  92.287    ujson  1.463  0.638  91.127    umsgpack  3.940  4.050  86.048    msgpack  1.342  0.388  86.048",
            "title": "The Results"
        },
        {
            "location": "/python_serializers/#what-does-this-mean",
            "text": "From the data above, we can see that pickle and msg-pack performed the best overall. In my initial research, I read several benchmarks claiming that JSON, particularly ujson, would provide enhanced performance over pickle - but that is not reflected in my test results at all. Why were my results different?  Most of the existing bench marks out there appear to be based on Python2 and these tests were performed on Python3 - which is a very important distinction. Python has two implementations of the pickle module, refered to as cPickle (backed by a C library for speed) and Pickle (a pure Python implementation for portability). In Python2, pickle is loaded by default and required the programmer to use a construct like:  try:\n   import cPickle as pickle\nexcept:\n   import pickle  In Python3, cPickle was renamed to _pickle and is now automatically loaded when present. If not present, Python will automatically fall back to the pure python implementation. Additionally, Python version 3.0 introduced Protocol 3 and version 3.4 introduced Protocol 4 - both adding significant enhancements and performance boosts to the binary pickle formats.  The end result of these improvements is that the old best practices for Python serialization don't hold up any more. This is how I will be making my choices:   If speed, convenience and flexibility are the most important, choose pickle.  Fastest round trip in my test cases  Python built-in, so  import pickle  just works  Most Python object support it already, so they automatically (de)serialize    If speed and portability are the most important, choose msg-pack  Second fastest round trip in my tests cases  Serial format has support in over 50 programming language  But requires a C-Module, so you might need a compiler if you can't find a binary release for your platform    If speed and JSON format are the most important, use ujson  Third fastest round trip  Outputs compliant JSON, which has become the de-facto exchange format  But requires a C-Module, so you might need a compiler if you can't find a binary release for your platform    If convenience and JSON format are the most important factors, use the built-in json module.  Fourth fastest round trip time  Outputs compliant JSON, which has become the de-facto exchange format  Python built-in, so  import json  just works",
            "title": "What does this mean?"
        },
        {
            "location": "/python_serializers/#for-the-essentialdb-use-case",
            "text": "EssentialDB doesn't support any partitioning or sharding currently (since it is generally meant to be used in memory) so the entire database is serialized and deserialized to disk at once - so speed (throughput) is the most important factor in many use cases. Many, but not all cases. Based on this, it makes sense that EssentialDB should support all of the serialization modules listed above. There are valid use cases to prefer any of the formats. Each of the module discussed here implement the same Python serialization interface:  # read - fp is a file object\ndata = serializer.load(fp)\n#write\nserializer.dump(fp, data)  By exploiting this, we can have pickle be the default serializer, but allow developers to specify alternate serializers.  The  pickle documentation   has a great discussion on when the differences in the formats:   JSON is a text serialization format (it outputs unicode text, although most of the time it is then encoded to utf-8), while pickle is a binary serialization format;  JSON is human-readable, while pickle is not;  JSON is interoperable and widely used outside of the Python ecosystem, while pickle is Python-specific;  JSON, by default, can only represent a subset of the Python built-in types, and no custom classes; pickle can represent an extremely large number of Python types (many of them automatically, by clever usage of Python\u2019s introspection facilities; complex cases can be tackled by implementing specific object APIs).",
            "title": "For the EssentialDB Use Case"
        }
    ]
}